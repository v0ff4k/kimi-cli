#!/bin/bash

# Coding Agent - Pure Bash CLI AI Assistant
# Version: 1.0.0
# Compatible with: Linux, macOS, Windows (with bash)

set -euo pipefail

# Global configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
CONFIG_DIR="$HOME/.config/coding-agent"
PROJECT_CONFIG_DIR=".coding-agent"
VERSION="1.3.5"

# Default configuration
DEFAULT_MODEL="kimi"
DEFAULT_SYSTEM_PROMPT=""
CONVERSATION_HISTORY=""
CONVERSATION_FILE="$PROJECT_CONFIG_DIR/conversation.json"
INTERACTIVE_MODE=false
VERBOSE=false

# API Configuration
OPENAI_API_URL="https://api.openai.com/v1/chat/completions"
ANTHROPIC_API_URL="https://api.anthropic.com/v1/messages"
GEMINI_API_BASE_URL="https://generativelanguage.googleapis.com/v1beta/models"
KIMI_API_URL="https://api.moonshot.cn/v1/chat/completions"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
NC='\033[0m' # No Color

# Utility functions
log() {
    echo -e "${CYAN}[$(date +'%H:%M:%S')]${NC} $1" >&2
}

error() {
    echo -e "${RED}[ERROR]${NC} $1" >&2
    exit 1
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1" >&2
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1" >&2
}

# Check dependencies
check_dependencies() {
    local missing_deps=()
    
    command -v curl >/dev/null 2>&1 || missing_deps+=("curl")
    command -v jq >/dev/null 2>&1 || missing_deps+=("jq")
    
    if [ ${#missing_deps[@]} -ne 0 ]; then
        error "Missing dependencies: ${missing_deps[*]}. Please install them first."
    fi
}

# Initialize configuration directories
init_config() {
    mkdir -p "$CONFIG_DIR"/{prompts,rules,memos}
    mkdir -p "$PROJECT_CONFIG_DIR"/{prompts,rules,memos}
    
    # Create default system prompt if it doesn't exist
    if [[ ! -f "$CONFIG_DIR/prompts/default.txt" ]]; then
        cat > "$CONFIG_DIR/prompts/default.txt" << 'EOF'
You are a helpful coding assistant. You provide clear, concise, and accurate help with programming tasks.

Key behaviors:
- Analyze code carefully before suggesting changes
- Explain your reasoning when helpful
- Follow best practices for the language being used
- Be direct and actionable in your responses
EOF
    fi
    
    # Create default config file
    if [[ ! -f "$CONFIG_DIR/config" ]]; then
        cat > "$CONFIG_DIR/config" << EOF
# Coding Agent Configuration
DEFAULT_MODEL="kimi"
DEFAULT_SYSTEM_PROMPT="default"
OPENAI_API_KEY=""
ANTHROPIC_API_KEY=""
GEMINI_API_KEY=""
KIMI_API_KEY=""
EOF
    fi
}

# Safe configuration parsing function
parse_config_safely() {
    local config_file="$1"
    
    if [[ ! -f "$config_file" ]]; then
        return 0
    fi
    
    # Whitelist of allowed configuration keys
    local allowed_keys=(
        "DEFAULT_MODEL"
        "DEFAULT_SYSTEM_PROMPT"
        "OPENAI_API_KEY"
        "ANTHROPIC_API_KEY"
        "GEMINI_API_KEY"
        "KIMI_API_KEY"
    )
    
    # Parse config file safely, only allowing whitelisted key=value pairs
    while IFS='=' read -r key value; do
        # Skip comments and empty lines
        [[ "$key" =~ ^[[:space:]]*# ]] && continue
        [[ -z "$key" ]] && continue
        
        # Remove quotes and whitespace
        key=$(echo "$key" | tr -d '[:space:]')
        value=$(echo "$value" | sed 's/^[\"'"'"']*//;s/[\"'"'"']*$//' | tr -d '[:space:]')
        
        # Check if key is in whitelist
        local key_allowed=false
        for allowed_key in "${allowed_keys[@]}"; do
            if [[ "$key" == "$allowed_key" ]]; then
                key_allowed=true
                break
            fi
        done
        
        if [[ "$key_allowed" == true ]]; then
            # Safely set the variable using declare
            declare -g "$key"="$value"
        else
            warning "Ignoring unknown config key: $key"
        fi
    done < "$config_file"
}

# Load configuration
load_config() {
    # Load global config
    parse_config_safely "$CONFIG_DIR/config"
    
    # Load project-specific config if it exists
    parse_config_safely "$PROJECT_CONFIG_DIR/config"
}

# Parse file references (@file/path/file.ext)
parse_file_references() {
    local input="$1"
    local output="$input"
    
    # Find all @file references
    local file_refs
    file_refs=$(echo "$input" | grep -oE '@[^[:space:]@]+\.[a-zA-Z0-9]+' || true)
    
    while IFS= read -r file_ref; do
        if [[ -n "$file_ref" ]]; then
            local file_path="${file_ref#@}"  # Remove @ prefix
            
            if [[ -f "$file_path" ]]; then
                local file_content
                file_content=$(cat "$file_path" 2>/dev/null || echo "[Error: Could not read file $file_path]")
                local context_block="

## File: $file_path
\`\`\`
$file_content
\`\`\`
"
                # Replace the file reference with the content
                output="${output//$file_ref/$context_block}"
            else
                warning "Referenced file not found: $file_path"
                output="${output//$file_ref/[File not found: $file_path]}"
            fi
        fi
    done <<< "$file_refs"
    
    echo "$output"
}

# Parse variable/symbol references (@varName)
parse_variable_references() {
    local input="$1"
    local output="$input"
    
    # Find all @variable references (alphanumeric + underscore, no file extensions)
    local var_refs
    var_refs=$(echo "$input" | grep -oE '@[a-zA-Z_][a-zA-Z0-9_]*' | grep -vE '@[^[:space:]@]+\.[a-zA-Z0-9]+' || true)
    
    while IFS= read -r var_ref; do
        if [[ -n "$var_ref" ]]; then
            local var_name="${var_ref#@}"  # Remove @ prefix
            
            # Search for the variable definition in current directory (portable approach)
            local search_result
            search_result=$(find . -type f \( -name "*.py" -o -name "*.js" -o -name "*.ts" -o -name "*.go" -o -name "*.php" -o -name "*.java" \) -exec grep -n "$var_name" {} + 2>/dev/null | head -10 || true)
            
            if [[ -n "$search_result" ]]; then
                local context_block="

## Variable/Symbol: $var_name
Found in:
\`\`\`
$search_result
\`\`\`
"
                output="${output//$var_ref/$context_block}"
            else
                output="${output//$var_ref/[Symbol '$var_name' not found in current directory]}"
            fi
        fi
    done <<< "$var_refs"
    
    echo "$output"
}

# Conversation history management
load_conversation_history() {
    if [[ -f "$CONVERSATION_FILE" ]]; then
        CONVERSATION_HISTORY=$(cat "$CONVERSATION_FILE" 2>/dev/null || echo "[]")
    else
        CONVERSATION_HISTORY="[]"
    fi
}

save_conversation_history() {
    if [[ -n "$CONVERSATION_HISTORY" ]]; then
        echo "$CONVERSATION_HISTORY" > "$CONVERSATION_FILE"
    fi
}

add_to_conversation() {
    local role="$1"
    local content="$2"
    
    if [[ -z "$CONVERSATION_HISTORY" || "$CONVERSATION_HISTORY" == "[]" ]]; then
        CONVERSATION_HISTORY="[]"
    fi
    
    CONVERSATION_HISTORY=$(echo "$CONVERSATION_HISTORY" | jq \
        --arg role "$role" \
        --arg content "$content" \
        '. + [{role: $role, content: $content}]')
}

clear_conversation() {
    CONVERSATION_HISTORY="[]"
    if [[ -f "$CONVERSATION_FILE" ]]; then
        rm "$CONVERSATION_FILE"
    fi
    success "Conversation history cleared"
}

# Get system prompt content
get_system_prompt() {
    local prompt_name="${1:-$DEFAULT_SYSTEM_PROMPT}"
    local prompt_file
    
    # Check project-specific prompt first
    if [[ -f "$PROJECT_CONFIG_DIR/prompts/${prompt_name}.txt" ]]; then
        prompt_file="$PROJECT_CONFIG_DIR/prompts/${prompt_name}.txt"
    elif [[ -f "$CONFIG_DIR/prompts/${prompt_name}.txt" ]]; then
        prompt_file="$CONFIG_DIR/prompts/${prompt_name}.txt"
    else
        error "System prompt '$prompt_name' not found"
    fi
    
    cat "$prompt_file"
}

# Make API call to OpenAI with conversation history
call_openai() {
    local system_prompt="$1"
    local user_prompt="$2"
    local model="${3:-gpt-4}"
    
    if [[ -z "$OPENAI_API_KEY" ]]; then
        error "OPENAI_API_KEY not set. Please configure it in $CONFIG_DIR/config"
    fi
    
    # Build messages array with conversation history
    local messages_json
    if [[ -n "$CONVERSATION_HISTORY" && "$CONVERSATION_HISTORY" != "[]" ]]; then
        # Add system message and conversation history, then current user message
        messages_json=$(echo "$CONVERSATION_HISTORY" | jq \
            --arg system "$system_prompt" \
            --arg user "$user_prompt" \
            '. = [{role: "system", content: $system}] + . + [{role: "user", content: $user}]')
    else
        # Just system and user message
        messages_json=$(jq -n \
            --arg system "$system_prompt" \
            --arg user "$user_prompt" \
            '[{role: "system", content: $system}, {role: "user", content: $user}]')
    fi
    
    local json_payload
    json_payload=$(jq -n \
        --arg model "$model" \
        --argjson messages "$messages_json" \
        '{
            model: $model,
            messages: $messages
        }')
    
    # Make API call with error handling
    local response
    local http_code
    response=$(curl -w "HTTPSTATUS:%{http_code}" -s -X POST "$OPENAI_API_URL" \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer $OPENAI_API_KEY" \
        -d "$json_payload")
    
    http_code=$(echo "$response" | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
    response=$(echo "$response" | sed -e 's/HTTPSTATUS:.*//g')
    
    if [[ "$http_code" -ne 200 ]]; then
        local error_msg
        error_msg=$(echo "$response" | jq -r '.error.message // "Unknown API error"' 2>/dev/null || echo "HTTP $http_code error")
        error "OpenAI API error (HTTP $http_code): $error_msg"
    fi
    
    local assistant_response
    assistant_response=$(echo "$response" | jq -r '.choices[0].message.content // "Error: No response content"')
    
    if [[ "$assistant_response" == "Error: No response content" ]]; then
        error "Invalid response format from OpenAI API"
    fi
    
    echo "$assistant_response"
}

# Make API call to Anthropic with conversation history
call_anthropic() {
    local system_prompt="$1"
    local user_prompt="$2"
    local model="${3:-claude-3-sonnet-20240229}"
    
    if [[ -z "$ANTHROPIC_API_KEY" ]]; then
        error "ANTHROPIC_API_KEY not set. Please configure it in $CONFIG_DIR/config"
    fi
    
    # Build messages array with conversation history
    local messages_json
    if [[ -n "$CONVERSATION_HISTORY" && "$CONVERSATION_HISTORY" != "[]" ]]; then
        # Add conversation history, then current user message
        messages_json=$(echo "$CONVERSATION_HISTORY" | jq \
            --arg user "$user_prompt" \
            '. + [{role: "user", content: $user}]')
    else
        # Just user message
        messages_json=$(jq -n \
            --arg user "$user_prompt" \
            '[{role: "user", content: $user}]')
    fi
    
    local json_payload
    json_payload=$(jq -n \
        --arg model "$model" \
        --arg system "$system_prompt" \
        --argjson messages "$messages_json" \
        --argjson max_tokens 4000 \
        '{
            model: $model,
            max_tokens: $max_tokens,
            system: $system,
            messages: $messages
        }')
    
    # Make API call with error handling
    local response
    local http_code
    response=$(curl -w "HTTPSTATUS:%{http_code}" -s -X POST "$ANTHROPIC_API_URL" \
        -H "Content-Type: application/json" \
        -H "x-api-key: $ANTHROPIC_API_KEY" \
        -H "anthropic-version: 2023-06-01" \
        -d "$json_payload")
    
    http_code=$(echo "$response" | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
    response=$(echo "$response" | sed -e 's/HTTPSTATUS:.*//g')
    
    if [[ "$http_code" -ne 200 ]]; then
        local error_msg
        error_msg=$(echo "$response" | jq -r '.error.message // "Unknown API error"' 2>/dev/null || echo "HTTP $http_code error")
        error "Anthropic API error (HTTP $http_code): $error_msg"
    fi
    
    local assistant_response
    assistant_response=$(echo "$response" | jq -r '.content[0].text // "Error: No response content"')
    
    if [[ "$assistant_response" == "Error: No response content" ]]; then
        error "Invalid response format from Anthropic API"
    fi
    
    echo "$assistant_response"
}

# Make API call to Gemini with error handling
call_gemini() {
    local system_prompt="$1"
    local user_prompt="$2"
    local model="${3:-gemini-pro}"
    
    if [[ -z "$GEMINI_API_KEY" ]]; then
        error "GEMINI_API_KEY not set. Please configure it in $CONFIG_DIR/config"
    fi
    
    # Combine system prompt, conversation history, and user prompt
    local combined_prompt="$system_prompt"
    
    if [[ -n "$CONVERSATION_HISTORY" && "$CONVERSATION_HISTORY" != "[]" ]]; then
        # Add conversation history
        local history_text
        history_text=$(echo "$CONVERSATION_HISTORY" | jq -r '.[] | "\\(.role): \\(.content)"' | tr '\n' ' ')
        combined_prompt="$combined_prompt

Conversation history:
$history_text"
    fi
    
    combined_prompt="$combined_prompt

$user_prompt"
    
    local json_payload
    json_payload=$(jq -n \
        --arg prompt "$combined_prompt" \
        '{
            contents: [{
                parts: [{text: $prompt}]
            }]
        }')
    
    # Make API call with error handling
    local response
    local http_code
    response=$(curl -w "HTTPSTATUS:%{http_code}" -s -X POST "$GEMINI_API_BASE_URL/$model:generateContent?key=$GEMINI_API_KEY" \
        -H "Content-Type: application/json" \
        -d "$json_payload")
    
    http_code=$(echo "$response" | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
    response=$(echo "$response" | sed -e 's/HTTPSTATUS:.*//g')
    
    if [[ "$http_code" -ne 200 ]]; then
        local error_msg
        error_msg=$(echo "$response" | jq -r '.error.message // "Unknown API error"' 2>/dev/null || echo "HTTP $http_code error")
        error "Gemini API error (HTTP $http_code): $error_msg"
    fi
    
    local assistant_response
    assistant_response=$(echo "$response" | jq -r '.candidates[0].content.parts[0].text // "Error: No response content"')
    
    if [[ "$assistant_response" == "Error: No response content" ]]; then
        error "Invalid response format from Gemini API"
    fi
    
    echo "$assistant_response"
}

# Make API call to Kimi with conversation history
call_kimi() {
    local system_prompt="$1"
    local user_prompt="$2"
    local model="${3:-moonshot-v1-8k}"
    
    if [[ -z "$KIMI_API_KEY" ]]; then
        error "KIMI_API_KEY not set. Please configure it in $CONFIG_DIR/config"
    fi
    
    # Build messages array with conversation history
    local messages_json
    if [[ -n "$CONVERSATION_HISTORY" && "$CONVERSATION_HISTORY" != "[]" ]]; then
        # Add system message and conversation history, then current user message
        messages_json=$(echo "$CONVERSATION_HISTORY" | jq \
            --arg system "$system_prompt" \
            --arg user "$user_prompt" \
            '. = [{role: "system", content: $system}] + . + [{role: "user", content: $user}]')
    else
        # Just system and user message
        messages_json=$(jq -n \
            --arg system "$system_prompt" \
            --arg user "$user_prompt" \
            '[{role: "system", content: $system}, {role: "user", content: $user}]')
    fi
    
    local json_payload
    json_payload=$(jq -n \
        --arg model "$model" \
        --argjson messages "$messages_json" \
        '{
            model: $model,
            messages: $messages
        }')
    
    # Make API call with error handling
    local response
    local http_code
    response=$(curl -w "HTTPSTATUS:%{http_code}" -s -X POST "$KIMI_API_URL" \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer $KIMI_API_KEY" \
        -d "$json_payload")
    
    http_code=$(echo "$response" | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
    response=$(echo "$response" | sed -e 's/HTTPSTATUS:.*//g')
    
    if [[ "$http_code" -ne 200 ]]; then
        local error_msg
        error_msg=$(echo "$response" | jq -r '.error.message // "Unknown API error"' 2>/dev/null || echo "HTTP $http_code error")
        error "Kimi API error (HTTP $http_code): $error_msg"
    fi
    
    local assistant_response
    assistant_response=$(echo "$response" | jq -r '.choices[0].message.content // "Error: No response content"')
    
    if [[ "$assistant_response" == "Error: No response content" ]]; then
        error "Invalid response format from Kimi API"
    fi
    
    echo "$assistant_response"
}

# Model ID mapping and validation
get_actual_model_id() {
    local input_model="$1"
    
    # Normalize input to lowercase
    local normalized="$(echo "$input_model" | tr '[:upper:]' '[:lower:]')"
    
    case "$normalized" in
        # OpenAI models
        openai|gpt)
            echo "gpt-4o"
            ;;
        gpt-4o|gpt-4o-mini|gpt-4|gpt-4-turbo|gpt-3.5-turbo)
            echo "$normalized"
            ;;
        # Anthropic models
        anthropic|claude)
            echo "claude-3-5-sonnet-20241022"
            ;;
        claude-3-5-sonnet*|claude-3-opus*|claude-3-sonnet*|claude-3-haiku*)
            echo "$normalized"
            ;;
        # Gemini models
        gemini|google)
            echo "gemini-pro"
            ;;
        gemini-pro|gemini-1.5-pro|gemini-1.5-flash)
            echo "$normalized"
            ;;
        # Kimi/Moonshot models  
        kimi|moonshot)
            echo "moonshot-v1-8k"
            ;;
        moonshot-v1-8k|moonshot-v1-32k|moonshot-v1-128k)
            echo "$normalized"
            ;;
        *)
            error "Unsupported model: $input_model. Supported: openai, anthropic, gemini, kimi or specific model IDs"
            ;;
    esac
}

# Get provider from model
get_model_provider() {
    local model="$1"
    
    case "$model" in
        gpt*)
            echo "openai"
            ;;
        claude*)
            echo "anthropic"
            ;;
        gemini*)
            echo "gemini"
            ;;
        moonshot*)
            echo "kimi"
            ;;
        *)
            error "Cannot determine provider for model: $model"
            ;;
    esac
}

# Route API call to appropriate service
call_model() {
    local input_model="$1"
    local system_prompt="$2"
    local user_prompt="$3"
    
    # Get actual model ID and provider
    local actual_model
    actual_model=$(get_actual_model_id "$input_model")
    
    local provider
    provider=$(get_model_provider "$actual_model")
    
    if [[ $VERBOSE == true ]]; then
        log "Using model: $actual_model (provider: $provider)"
    fi
    
    case "$provider" in
        openai)
            call_openai "$system_prompt" "$user_prompt" "$actual_model"
            ;;
        anthropic)
            call_anthropic "$system_prompt" "$user_prompt" "$actual_model"
            ;;
        gemini)
            call_gemini "$system_prompt" "$user_prompt" "$actual_model"
            ;;
        kimi)
            call_kimi "$system_prompt" "$user_prompt" "$actual_model"
            ;;
        *)
            error "Unsupported provider: $provider"
            ;;
    esac
}

# Interactive mode with conversation history
interactive_mode() {
    echo -e "${PURPLE}Coding Agent v$VERSION - Interactive Mode${NC}"
    echo -e "${CYAN}Current model: $DEFAULT_MODEL${NC}"
    echo -e "${CYAN}Type 'exit' to quit, 'help' for commands, 'clear' to clear history${NC}"
    echo ""
    
    # Load conversation history
    load_conversation_history
    
    # Show conversation history if it exists
    if [[ -n "$CONVERSATION_HISTORY" && "$CONVERSATION_HISTORY" != "[]" ]]; then
        local history_count
        history_count=$(echo "$CONVERSATION_HISTORY" | jq length)
        echo -e "${CYAN}Loaded $history_count previous messages from conversation history${NC}"
        echo ""
    fi
    
    while true; do
        echo -ne "${GREEN}> ${NC}"
        read -r input
        
        case "$input" in
            exit|quit)
                save_conversation_history
                echo "Goodbye!"
                break
                ;;
            help)
                show_interactive_help
                ;;
            clear)
                clear_conversation
                ;;
            "")
                continue
                ;;
            *)
                # Add user message to conversation
                add_to_conversation "user" "$input"
                
                # Get response
                local response
                response=$(process_prompt "$input" "$DEFAULT_MODEL")
                
                # Add assistant response to conversation
                add_to_conversation "assistant" "$response"
                
                # Save conversation history
                save_conversation_history
                
                echo "$response"
                echo ""
                ;;
        esac
    done
}

# Process a prompt with file/variable references
process_prompt() {
    local user_input="$1"
    local model="${2:-$DEFAULT_MODEL}"
    
    if [[ $VERBOSE == true ]]; then
        log "Processing prompt with model: $model"
        log "Parsing file and variable references..."
    fi
    
    # Parse file references
    user_input=$(parse_file_references "$user_input")
    
    # Parse variable references  
    user_input=$(parse_variable_references "$user_input")
    
    # Get system prompt
    local system_prompt
    system_prompt=$(get_system_prompt)
    
    if [[ $VERBOSE == true ]]; then
        log "Making API call..."
    fi
    
    # Make API call
    local response
    response=$(call_model "$model" "$system_prompt" "$user_input")
    
    echo "$response"
}

# Show interactive help
show_interactive_help() {
    cat << EOF
${PURPLE}Interactive Mode Commands:${NC}
  help      - Show this help
  clear     - Clear conversation history
  exit/quit - Exit interactive mode
  
${YELLOW}Special features in interactive mode:${NC}
  - Conversation history is automatically maintained
  - Use @file/path/file.ext to include file contents
  - Use @variableName to search for variable definitions
EOF
}

# Show help
show_help() {
    cat << EOF
${PURPLE}Coding Agent v$VERSION${NC} - Pure Bash CLI AI Assistant

${YELLOW}Usage:${NC}
  $0 [OPTIONS] "your prompt here"
  $0 --interactive
  
${YELLOW}Options:${NC}
  -m, --model MODEL     AI model to use (openai, anthropic, gemini, kimi)
  -s, --system PROMPT   System prompt name to use
  -i, --interactive     Start interactive mode
  -v, --verbose         Verbose output
  -h, --help           Show this help
  --version            Show version
  
${YELLOW}File References:${NC}
  Use @file/path/file.ext to include file contents in your prompt
  Example: "Review @src/main.py and suggest improvements"
  
${YELLOW}Variable References:${NC}
  Use @variableName to search for variable definitions
  Example: "Explain what @handleRequest does"
  
${YELLOW}Configuration:${NC}
  Global config: $CONFIG_DIR/config
  Project config: $PROJECT_CONFIG_DIR/config
  System prompts: $CONFIG_DIR/prompts/
  
${YELLOW}Examples:${NC}
  $0 "Write a hello world program in Python"
  $0 -m anthropic "Explain this code: @main.py"
  $0 --interactive
EOF
}

# Main function
main() {
    local model="$DEFAULT_MODEL"
    local system_prompt=""
    local prompt=""
    
    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -m|--model)
                model="$2"
                shift 2
                ;;
            -s|--system)
                system_prompt="$2"
                shift 2
                ;;
            -i|--interactive)
                INTERACTIVE_MODE=true
                shift
                ;;
            -v|--verbose)
                VERBOSE=true
                shift
                ;;
            -h|--help)
                show_help
                exit 0
                ;;
            --version)
                echo "Coding Agent v$VERSION"
                exit 0
                ;;
            *)
                prompt="$1"
                shift
                ;;
        esac
    done
    
    # Initialize
    check_dependencies
    init_config
    load_config
    
    # Set conversation file path after config is loaded
    CONVERSATION_FILE="$PROJECT_CONFIG_DIR/conversation.json"
    
    # Set model if provided
    if [[ -n "$model" ]]; then
        DEFAULT_MODEL="$model"
    fi
    
    # Set system prompt if provided
    if [[ -n "$system_prompt" ]]; then
        DEFAULT_SYSTEM_PROMPT="$system_prompt"
    fi
    
    if [[ $INTERACTIVE_MODE == true ]]; then
        interactive_mode
    elif [[ -n "$prompt" ]]; then
        process_prompt "$prompt" "$DEFAULT_MODEL"
    else
        echo -e "${RED}Error: No prompt provided${NC}"
        echo "Use --help for usage information"
        exit 1
    fi
}

# Run main function if script is executed directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
